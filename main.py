import os
import json
import asyncio
import random
import aiohttp
import aiofiles
import logging
import sys
from urllib.parse import urljoin
from bs4 import BeautifulSoup
from tqdm import tqdm
from mutagen.id3 import ID3, TIT2, TPE1, TALB, COMM
from mutagen.mp3 import MP3

# ===== –ù–ê–°–¢–†–û–ô–ö–ò =====
BASE_URL = "https://tarat.ru"
MUSIC_URL = f"{BASE_URL}/music"
OUTPUT_DIR = "tarat_tracks"
TRACKS_CACHE_FILE = "tracks.json"
ERROR_LOG_FILE = "errors.log"
MAX_CONCURRENT_DOWNLOADS = 6

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    filename=ERROR_LOG_FILE,
    filemode='w',
    level=logging.ERROR,
    format='%(asctime)s - %(message)s',
    datefmt='%H:%M:%S'
)

# –°–æ—Å—Ç–æ—è–Ω–∏–µ —Å–ª–æ—Ç–æ–≤: (track_str, total_bytes, current_bytes)
slot_states = [None] * MAX_CONCURRENT_DOWNLOADS  # None –∏–ª–∏ (name, total, current)
slot_lock = asyncio.Lock()

# –ì–ª–æ–±–∞–ª—å–Ω—ã–µ –¥–ª—è –æ–±–ª–æ–∂–µ–∫
downloaded_covers = set()
cover_lock = asyncio.Lock()

def sanitize_filename(name):
    name = "".join(c for c in name if c not in r'<>:"/\|?*').strip()
    name = " ".join(name.split())
    name = name.replace(" - ", "-").replace(" ‚Äì ", "-")
    return name

def build_expected_filepath(singer_name, title):
    singer_clean = sanitize_filename(singer_name)
    title_clean = sanitize_filename(title)
    filename = f"{singer_clean} - {title_clean}.mp3"
    folder = os.path.join(OUTPUT_DIR, singer_clean)
    os.makedirs(folder, exist_ok=True)
    return os.path.join(folder, filename)

def write_id3_tags(filepath, artist, title, source_url):
    try:
        audio = MP3(filepath, ID3=ID3)
        try:
            audio.add_tags()
        except:
            pass
        audio.tags.add(TPE1(encoding=3, text=artist))
        audio.tags.add(TIT2(encoding=3, text=title))
        audio.tags.add(TALB(encoding=3, text=artist))
        audio.tags.add(COMM(encoding=3, lang='rus', text=source_url))
        audio.save()
    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ –∑–∞–ø–∏—Å–∏ ID3-—Ç–µ–≥–æ–≤ –≤ {os.path.basename(filepath)}: {e}")

def get_random_headers():
    return {
        "User-Agent": random.choice([
            "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/124.0.0.0 Safari/537.36",
            "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.5 Safari/605.1.15",
            "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/123.0.0.0 Safari/537.36"
        ]),
        "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8",
        "Accept-Language": "ru-RU,ru;q=0.9,en-US;q=0.8,en;q=0.7",
        "Referer": BASE_URL,
        "DNT": "1",
        "Connection": "keep-alive",
    }

async def fetch_html(session: aiohttp.ClientSession, url: str, timeout: int = 15):
    try:
        async with session.get(url, headers=get_random_headers(), timeout=timeout) as resp:
            if resp.status == 200:
                return await resp.text()
            else:
                logging.error(f"HTTP {resp.status} –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ HTML: {url}")
                return None
    except asyncio.TimeoutError:
        logging.error(f"–¢–∞–π–º-–∞—É—Ç –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ HTML: {url}")
        return None
    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ HTML {url}: {e}")
        return None

async def safe_get_content_length(resp):
    try:
        return int(resp.headers.get('content-length', 0))
    except (ValueError, TypeError):
        return 0

async def download_track(semaphore, session, track, slot_index, pbar_track):
    global downloaded_covers
    singer_name, title, mp3_url, cover_url = track
    filepath = build_expected_filepath(singer_name, title)
    track_str = f"{singer_name} - {title}"

    if os.path.exists(filepath):
        async with cover_lock:
            if singer_name not in downloaded_covers and cover_url:
                await download_cover(session, singer_name, cover_url)
        return True

    async with semaphore:
        # –û–±–Ω–æ–≤–ª—è–µ–º –æ–ø–∏—Å–∞–Ω–∏–µ –ø—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä–∞
        pbar_track.set_description(f"{track_str[:50]}")
        pbar_track.reset()

        try:
            async with session.get(mp3_url, headers=get_random_headers(), timeout=45) as resp:
                if resp.status != 200:
                    logging.error(f"HTTP {resp.status} –ø—Ä–∏ —Å–∫–∞—á–∏–≤–∞–Ω–∏–∏ {track_str}")
                    return False

                total_size = await safe_get_content_length(resp)
                pbar_track.total = total_size or 1

                # –°–∫–∞—á–∏–≤–∞–Ω–∏–µ –ø–æ—Ä—Ü–∏—è–º–∏
                chunk_size = 8192
                downloaded = 0
                async with aiofiles.open(filepath, "wb") as f:
                    async for chunk in resp.content.iter_chunked(chunk_size):
                        await f.write(chunk)
                        downloaded += len(chunk)
                        pbar_track.update(len(chunk))

            # –û–±–ª–æ–∂–∫–∞
            async with cover_lock:
                if singer_name not in downloaded_covers and cover_url:
                    await download_cover(session, singer_name, cover_url)

            write_id3_tags(filepath, singer_name, title, mp3_url)
            return True

        except Exception as e:
            logging.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–∫–∞—á–∏–≤–∞–Ω–∏–∏ {track_str}: {e}")
            return False

async def download_cover(session, singer_name, cover_url):
    if not cover_url:
        return
    singer_clean = sanitize_filename(singer_name)
    folder = os.path.join(OUTPUT_DIR, singer_clean)
    cover_filename = f"{singer_clean}_cover.jpg"
    cover_path = os.path.join(folder, cover_filename)
    if os.path.exists(cover_path):
        return
    try:
        async with session.get(cover_url, headers=get_random_headers(), timeout=30) as resp:
            if resp.status == 200:
                os.makedirs(folder, exist_ok=True)
                async with aiofiles.open(cover_path, "wb") as f:
                    await f.write(await resp.read())
    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è –æ–±–ª–æ–∂–∫–∏ {singer_name}: {e}")

async def get_all_singer_urls(session: aiohttp.ClientSession):
    singer_urls = set()
    page = 1
    while True:
        url = f"{MUSIC_URL}?page={page}" if page > 1 else MUSIC_URL
        html = await fetch_html(session, url)
        if not html:
            break
        soup = BeautifulSoup(html, "html.parser")
        links = soup.select('h4.property-item-title a[href^="/music/"]')
        if not links:
            break
        for link in links:
            href = link.get("href")
            if href and not href.endswith("/music"):
                singer_urls.add(urljoin(BASE_URL, href))
        if not soup.select('ul.pagination a[rel="next"]'):
            break
        page += 1
        await asyncio.sleep(random.uniform(1.0, 2.0))
    return sorted(singer_urls)

async def collect_all_tracks(session: aiohttp.ClientSession, singer_urls):
    all_tracks = []
    async def process_singer(singer_url):
        html = await fetch_html(session, singer_url)
        if not html:
            return []
        soup = BeautifulSoup(html, "html.parser")
        singer_name_tag = soup.select_one("div.page-title h1")
        singer_name = singer_name_tag.get_text(strip=True) if singer_name_tag else "Unknown"
        cover_img = soup.select_one('img.img-fluid')
        cover_url = None
        if cover_img and cover_img.get("src"):
            cover_url = urljoin(BASE_URL, cover_img["src"])
        track_elements = soup.select('li.song i.play[data-file][data-song-title]')
        tracks = []
        for el in track_elements:
            title = el.get("data-song-title", "").strip()
            file_path = el.get("data-file", "").strip()
            if title and file_path:
                mp3_url = urljoin(BASE_URL, file_path)
                tracks.append((singer_name, title, mp3_url, cover_url))
        await asyncio.sleep(random.uniform(0.8, 1.5))
        return tracks
    from tqdm.asyncio import tqdm_asyncio
    tasks = [process_singer(url) for url in singer_urls]
    results = await tqdm_asyncio.gather(*tasks, desc="–°–±–æ—Ä —Ç—Ä–µ–∫–æ–≤")
    for tracks in results:
        all_tracks.extend(tracks)
    return all_tracks

async def main():
    os.makedirs(OUTPUT_DIR, exist_ok=True)

    # –ó–∞–≥—Ä—É–∑–∫–∞ –∫—ç—à–∞
    if os.path.exists(TRACKS_CACHE_FILE):
        print(f"üìÇ –ó–∞–≥—Ä—É–∑–∫–∞ –∫—ç—à–∞ —Ç—Ä–µ–∫–æ–≤ –∏–∑ {TRACKS_CACHE_FILE}")
        try:
            with open(TRACKS_CACHE_FILE, "r", encoding="utf-8") as f:
                all_tracks = json.load(f)
            print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ —Ç—Ä–µ–∫–æ–≤ –∏–∑ –∫—ç—à–∞: {len(all_tracks)}")
        except Exception as e:
            logging.error(f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è –∫—ç—à–∞: {e}")
            all_tracks = []
    else:
        print("üåê –ö—ç—à –Ω–µ –Ω–∞–π–¥–µ–Ω. –ü–∞—Ä—Å–∏–Ω–≥ —Å–∞–π—Ç–∞...")
        connector = aiohttp.TCPConnector(limit=20)
        timeout = aiohttp.ClientTimeout(total=30)
        async with aiohttp.ClientSession(connector=connector, timeout=timeout) as session:
            try:
                singer_urls = await get_all_singer_urls(session)
                print(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ –∏—Å–ø–æ–ª–Ω–∏—Ç–µ–ª–µ–π: {len(singer_urls)}")
                all_tracks = await collect_all_tracks(session, singer_urls)
            except Exception as e:
                logging.critical(f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –ø–∞—Ä—Å–∏–Ω–≥–µ: {e}")
                return
        try:
            with open(TRACKS_CACHE_FILE, "w", encoding="utf-8") as f:
                json.dump(all_tracks, f, ensure_ascii=False, indent=2)
            print(f"üíæ –ö—ç—à —Å–æ—Ö—Ä–∞–Ω—ë–Ω –≤ {TRACKS_CACHE_FILE}")
        except Exception as e:
            logging.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –∫—ç—à: {e}")

    total = len(all_tracks)
    if total == 0:
        print("‚ùå –ù–µ—Ç —Ç—Ä–µ–∫–æ–≤ –¥–ª—è —Å–∫–∞—á–∏–≤–∞–Ω–∏—è.")
        return

    # –°–æ–∑–¥–∞—ë–º –ø—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä—ã
    pbar_main = tqdm(total=total, desc="–û–±—â–∏–π –ø—Ä–æ–≥—Ä–µ—Å—Å", unit="—Ç—Ä–µ–∫", position=0, leave=True)
    pbar_tracks = []
    for i in range(MAX_CONCURRENT_DOWNLOADS):
        pbar = tqdm(
            desc="‚Äî",
            total=1,
            unit="B",
            unit_scale=True,
            unit_divisor=1024,
            position=i + 1,
            leave=False,
            bar_format='{desc}: {percentage:3.0f}%|{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_fmt}]'
        )
        pbar_tracks.append(pbar)

    semaphore = asyncio.Semaphore(MAX_CONCURRENT_DOWNLOADS)
    connector = aiohttp.TCPConnector(limit_per_host=8, limit=20)
    timeout = aiohttp.ClientTimeout(total=60)

    async with aiohttp.ClientSession(connector=connector, timeout=timeout) as session:
        tasks = []
        for i, track in enumerate(all_tracks):
            slot_idx = i % MAX_CONCURRENT_DOWNLOADS
            task = download_track(semaphore, session, track, slot_idx, pbar_tracks[slot_idx])
            tasks.append(task)

        success_count = 0
        try:
            # results = await asyncio.gather(*tasks, return_exceptions=True)
            # for res in results:
            #     if res is True:
            #         success_count += 1
            #     pbar_main.update(1)
            for coro in asyncio.as_completed(tasks):
                try:
                    result = await coro
                    if result is True:
                        success_count += 1
                except Exception as e:
                    logging.error(f"–ò—Å–∫–ª—é—á–µ–Ω–∏–µ –≤ –∑–∞–¥–∞—á–µ: {e}")
                    # –ú–æ–∂–Ω–æ —Å—á–∏—Ç–∞—Ç—å –∫–∞–∫ –Ω–µ—É–¥–∞—á–Ω—É—é –∑–∞–≥—Ä—É–∑–∫—É, –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
                finally:
                    pbar_main.update(1)
        except KeyboardInterrupt:
            print("\n\nüõë –ü–æ–ª—É—á–µ–Ω —Å–∏–≥–Ω–∞–ª –ø—Ä–µ—Ä—ã–≤–∞–Ω–∏—è. –û—Ç–º–µ–Ω–∞ –∑–∞–¥–∞—á...")
            for task in asyncio.all_tasks():
                if task is not asyncio.current_task():
                    task.cancel()
            await asyncio.gather(*asyncio.all_tasks(), return_exceptions=True)
        finally:
            pbar_main.close()
            for p in pbar_tracks:
                p.close()

    # –ò—Ç–æ–≥
    print(f"\n‚úÖ –£—Å–ø–µ—à–Ω–æ —Å–∫–∞—á–∞–Ω–æ: {success_count} –∏–∑ {total}")
    print(f"üìÅ –§–∞–π–ª—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {os.path.abspath(OUTPUT_DIR)}")
    print(f"üìÑ –û—à–∏–±–∫–∏ –∑–∞–ø–∏—Å–∞–Ω—ã –≤: {os.path.abspath(ERROR_LOG_FILE)}")
    print("üéµ –í—Å–µ —Ç—Ä–µ–∫–∏ —Å–æ–¥–µ—Ä–∂–∞—Ç ID3-—Ç–µ–≥–∏.")

if __name__ == "__main__":
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        print("\nüõë –ü—Ä–æ–≥—Ä–∞–º–º–∞ –ø—Ä–µ—Ä–≤–∞–Ω–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º (Ctrl+C).")
        sys.exit(0)
    except Exception as e:
        logging.critical(f"–ù–µ–æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω–æ–µ –∏—Å–∫–ª—é—á–µ–Ω–∏–µ: {e}")
        print(f"\nüí• –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}")
        sys.exit(1)